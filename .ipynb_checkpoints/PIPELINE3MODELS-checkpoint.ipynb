{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')  # change the default style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv data into pandas dataframe\n",
    "df = pd.read_csv('projectdataset-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data by separating X and y\n",
    "# dropping Y variable\n",
    "\n",
    "# axis = 1 below means dropping by columns, 0 means by rows\n",
    "X = df.drop(['Class'], axis=1)\n",
    "y = df['Class']\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36168, 16)\n",
      "(9043, 16)\n",
      "(36168,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training set and a test set. \n",
    "# Any number for the random_state is fine, see 42: https://en.wikipedia.org/wiki/42_(number) \n",
    "# We choose to use 20% (test_size=0.2) of the data set as the test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "##added stratify option above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will train our decision tree classifier with the following features:\n",
    "\n",
    "num_features = ['age', 'balance', 'day', 'duration', 'pdays' ]\n",
    "cat_features = ['housing','month','poutcome', 'contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Create the preprocessing pipeline for numerical features\n",
    "# There are two steps in this pipeline\n",
    "# Pipeline(steps=[(name1, transform1), (name2, transform2), ...]) \n",
    "# NOTE the step names can be arbitrary\n",
    "\n",
    "# Step 1 is what we discussed before - filling the missing values if any using mean\n",
    "# Step 2 is feature scaling via standardization - making features look like normal-distributed \n",
    "# see sandardization: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('num_imputer', SimpleImputer()),  # we will tune differet strategies later\n",
    "        ('scaler', StandardScaler()),\n",
    "        ]\n",
    ")\n",
    "\n",
    "# Create the preprocessing pipelines for the categorical features\n",
    "# There are two steps in this pipeline:\n",
    "# Step 1: filling the missing values if any using the most frequent value\n",
    "# Step 2: one hot encoding\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Assign features to the pipelines and Combine two pipelines to form the preprocessor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_pipeline', num_pipeline, num_features),\n",
    "        ('cat_pipeline', cat_pipeline, cat_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model to use, which is DecisionTreeClassifier\n",
    "# Make a full pipeline by combining preprocessor and the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline_dt = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf_dt', DecisionTreeClassifier()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we show how to use GridSearch with K-fold cross validation (K=10) to fine tune the model\n",
    "# we use the accuracy as the scoring metric with training score return_train_score=True\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set up the values of hyperparameters you want to evaluate\n",
    "# here you must use the step names as the prefix followed by two under_scores to sepecify the parameter names and the \"full path\" of the steps\n",
    "\n",
    "# we are trying 2 different impputer strategies \n",
    "# 2x5 different decision tree models with different parameters\n",
    "# in total we are trying 2x2x5 = 20 different combinations\n",
    "\n",
    "param_grid_dt = [\n",
    "    {\n",
    "        'preprocessor__num_pipeline__num_imputer__strategy': ['mean', 'median'],\n",
    "        'clf_dt__criterion': ['gini', 'entropy'], \n",
    "        'clf_dt__max_depth': [3, 4, 5, 6, 7],\n",
    "   \n",
    "    }\n",
    "]\n",
    "\n",
    "# set up the grid search \n",
    "grid_search_dt = GridSearchCV(pipeline_dt, param_grid_dt, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using the full pipeline\n",
    "grid_search_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the best performing parameter combination\n",
    "grid_search_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build-in CV results keys\n",
    "sorted(grid_search_dt.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test score for the 20 decision tree models\n",
    "grid_search_dt.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best decistion tree model test score\n",
    "grid_search_dt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best test score\n",
    "print('best dt score is: ', grid_search_dt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best model\n",
    "# the best parameters are shown, note SimpleImputer() implies that mean strategry is used\n",
    "clf_best = grid_search_dt.best_estimator_\n",
    "clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final test on the testing set\n",
    "# To predict on new data: simply calling the predict method \n",
    "# the full pipeline steps will be applied to the testing set followed by the prediction\n",
    "y_pred = clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best.named_steps['preprocessor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = list(clf_best.named_steps['preprocessor'].named_transformers_['cat_pipeline'].named_steps['onehot'].get_feature_names(input_features=cat_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = clf_best.named_steps[\"clf_dt\"].feature_importances_\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_list = list(num_features)\n",
    "numeric_features_list.extend(onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5 as eli5\n",
    "eli5.explain_weights(clf_best.named_steps[\"clf_dt\"], top=50, feature_names=numeric_features_list, feature_filter=lambda x: x != '<BIAS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(i, index=numeric_features_list, columns=['importance'])\n",
    "r\n",
    "\n",
    "print(r.sort_values('importance', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the Model\n",
    "The following code shows how to save the trained model as a pickle file, which can be loaded in to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "# rf pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf_rf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# here we are trying 2x3 different rf models\n",
    "param_grid_rf = [\n",
    "    {\n",
    "        'clf_rf__criterion': ['gini', 'entropy'], \n",
    "        'clf_rf__n_estimators': [50, 100, 150],  \n",
    "    }\n",
    "]\n",
    "\n",
    "# set up the grid search \n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train the model using the full pipeline\n",
    "grid_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best = grid_search_dt.best_estimator_\n",
    "y_pred = clf_best.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banker = X_test.iloc[23].to_frame().T\n",
    "banker.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banker.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = clf_best.predict(banker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try SVM classifer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVC pipeline\n",
    "pipeline_svc = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf_svc', SVC()),\n",
    "])\n",
    "\n",
    "# here we are trying three different kernel and three degree values for polynomail kernel\n",
    "# in total 5 different combinations\n",
    "param_grid_svc = [\n",
    "    {\n",
    "        'clf_svc__kernel': ['linear', 'poly', 'rbf'], \n",
    "        'clf_svc__degree': [3, 4, 5],  # only for poly kernel\n",
    "    }\n",
    "]\n",
    "\n",
    "# set up the grid search \n",
    "grid_search_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using the full pipeline\n",
    "grid_search_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best test score\n",
    "grid_search_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "'''\n",
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=3\n",
    ")\n",
    "'''\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA()), \n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
    "    'model__max_depth': [2, 3, 5, 7, 10],\n",
    "    'model__n_estimators': [10, 100, 500],\n",
    "}\n",
    "\n",
    "grid_xgboost = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "#%%time\n",
    "grid_xgboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "mean_score = grid.cv_results_[\"mean_test_score\"][grid_xgboost.best_index_]\n",
    "std_score = grid.cv_results_[\"std_test_score\"][grid_xgboost.best_index_]\n",
    "\n",
    "grid_xgboost.best_params_, mean_score, std_score #, best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_score_.best_params_}\")\n",
    "print(f\"Mean CV score: {mean_score: .6f}\")\n",
    "print(f\"Standard deviation of CV score: {std_score: .6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best test score\n",
    "print('best dt score is: ', grid_search_dt.best_score_)\n",
    "print('best svc score is: ', grid_search_svc.best_score_)\n",
    "print('best rf score is: ', grid_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best model\n",
    "# the best parameters are shown, note SimpleImputer() implies that mean strategry is used\n",
    "clf_best = grid_search_rf.best_estimator_\n",
    "clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle file\n",
    "import joblib\n",
    "joblib.dump(clf_best, \"clf-best.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from a pickle file\n",
    "saved_tree_clf = joblib.load(\"clf-best.pickle\")\n",
    "saved_tree_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banker1 = pd.DataFrame(\n",
    "    {   'age' : 33, \n",
    "        'job' : 'self-employed',\n",
    "        'marital' : 'married',\n",
    "        'education' : 'secondary', \n",
    "        'default' : 'no', \n",
    "        'balance' : 0, \n",
    "        'housing' : 'no',\n",
    "        'loan' : 'no',\n",
    "        'contact' : 'cellular',\n",
    "        'day' : 18, \n",
    "        'month' : 'aug', \n",
    "        'duration' : 73,\n",
    "        'campaign' : 7,\n",
    "        'pdays': -1, \n",
    "        'previous' : 0,\n",
    "        'poutcome' : ['success']       \n",
    "     \n",
    "     \n",
    "    })\n",
    "\n",
    "clf_best.predict(banker1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best.predict(banker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final test on the testing set\n",
    "# To predict on new data: simply calling the predict method \n",
    "# the full pipeline steps will be applied to the testing set followed by the prediction\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "# calculate accuracy, Note: y_test is the ground truth for the tesing set\n",
    "# we have similiar score for the testing set as the cross validation score - good\n",
    "\n",
    "#print(f'Accuracy Score : {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_best.named_steps['preprocessor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
